---
title: "HW 6 Solutions"
author: "Tom Fletcher"
date: "November 21, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, comment = "")
```

# Problem 1

I'm using $S$ = "smoker" and $H$ = "heart attack".

## (a)

$P(S = 1) = P(S = 1, H = 1) + P(S = 1, H = 0) = 0.47$

## (b)

$P(H = 1) = P(S = 1, H = 1) + P(S = 0, H = 1) = 0.06$

## (c)

$$P(H = 1 \mid S = 1) = P(S = 1, H = 1) / P(S = 1) = 0.03 / 0.47$$
$$P(H = 1 \mid S = 0) = P(S = 0, H = 1) / P(S = 0) = 0.03 / 0.50$$
So, if you are smoker, your probability of a heart attack is higher

## (d)

$$P(S = 1 \mid H = 1) = P(S = 1, H = 1) / P(H = 1) = 0.03 / 0.06 = 0.5$$

## (e)

No, they are dependent: $P(H = 1) \neq P(H = 1 \mid S = 1)$ above.

## (f)

Remember the expected value for a Bernoulli is just $p$\\
$E[S] = P(S = 1) = 0.47$, $E[H] = P(H = 1) = 0.06$, $E[SH] = P(S = 1, H = 1) =
0.03$
$$\mathrm{Cov}(S, H) = E[SH] - E[S] E[H] = 0.03 - 0.06 \times 0.47 = 0.0018$$

## (g)

Remember the variance for a Bernoulli variable is $p (1 - p)$.

$$\mathrm{Var}(S) = P(S = 1) (1 - P(S = 1)) = 0.47 \times 0.53 = 0.2491$$
$$\mathrm{Var}(H) = P(H = 1) (1 - P(H = 1)) = 0.06 \times 0.94 = 0.0564$$

$$
\begin{aligned}
\rho(S, H) &= \frac{\mathrm{Cov}(S, H)}{\sqrt{\mathrm{Var}(S) \mathrm{Var}(H)}}\\
&= \frac{0.0018}{\sqrt{0.2491 \times 0.0564}}\\
&= 0.0152
\end{aligned}
$$

# Problem 2

First, we'll sample from the 4 possible joint outcomes, with probabilities given in the table.

```{r}
Omega = 1:4
N = 100000
x = sample(Omega, size = N, prob = c(0.03, 0.03, 0.44, 0.50), replace = TRUE)
```

Now convert these joint outcomes into the smoker and heart attack outcomes.

```{r}
smoker = (x == 1) | (x == 3)
heart = (x == 1) | (x == 2)
```

## (a)

Use the conditional probability formula for $P(S = 1 \mid H = 1)$. Notice that you can think of this formula as "out of the number of people who had a heart attack, how many of them were also smokers."

```{r}
sum(smoker & heart) / sum(heart)
```

## (b)

This is just the R call:

```{r}
cov(smoker, heart)
```

## (c)

Again, just call the R function:

```{r}
cor(smoker, heart)
```

# Problem 3

## (a)

$$
\begin{aligned}
1 &= \int_0^1 \int_0^1 k (x + y)\, dx\, dy\\
&= \int_0^1 k \left(\frac{x^2}{2} + xy\right) \, dy \Bigg|_{x=0}^{x=1}\\
&= k \left(\frac{x^2 y}{2} + \frac{x y^2}{2}\right) \Bigg|_{x=0}^{x=1} \Bigg|_{y=0}^{y=1}\\
&= k
\end{aligned}
$$

So, $k = 1$

## (b)

$$
\begin{aligned}
P\left(X \geq \frac{1}{4}, Y \leq \frac{1}{2}\right) &= \int_{1/4}^1
\int_0^{1/2} (x + y)\, dy\, dx\\
&= \left( \frac{x^2 y}{2} + \frac{x y^2}{2} \right) \Bigg|_{x=1/4}^{x=1} \Bigg|_{y=0}^{y=1/2}\\
&= \frac{1}{2}(1^2 y + y^2 - (1/4)^2 y - (1/4) y^2)\Bigg|_{y=0}^{y=1/2}\\
&= \frac{1}{2}((1/2) + (1/2)^2 - (1/4)^2 (1/2) - (1/4)- (1/2)^2)\\
&= \frac{21}{64} = `r 21/64`
\end{aligned}
$$

## (c)

$$f_X(x) = \int_0^1 (x + y)\, dy = x + \frac{1}{2}$$

## (d)

$$f_Y(y) = \int_0^1 (x + y)\, dx = y + \frac{1}{2}$$

## (e)

$$f_{X \mid Y=\frac{1}{2}}(x) = \frac{f_{X,Y}\left(x, \frac{1}{2}\right)}{f_Y\left(\frac{1}{2}\right)} = x + \frac{1}{2}$$

$$
\begin{aligned}
P\left(X \leq \frac{1}{4} \mid Y = \frac{1}{2}\right) &=
\int_0^{1/4} f_{X \mid Y = \frac{1}{2}}(x)\, dx\\
&= \int_0^{1/4} x + \frac{1}{2}\, dx\\
&= \frac{x^2}{2} + \frac{x}{2} \Big|_{x = 0}^{x = 1/4}\\
&= \frac{5}{32} \approx `r 5/32`
\end{aligned}
$$

## (f)

No, it is not the case that $f_{X,Y}(x, y) = f_X(x) f_Y(y)$ (verified from
the above marginals).

## (g)

Using formula $\mathrm{Cov}(X, Y) = E[XY] - E[X] E[Y]$.

$$
\begin{aligned}
E[XY] &= \int_0^1 \int_0^1 xy (x + y) dx dy\\
&= \int_0^1 \frac{1}{3} x^3 y + \frac{1}{2} x^2 y^2 dy \Big|_{x=0}^{x=1}\\
&= \frac{1}{6} (x^3 y^2 + x^2 y^3) \Big|_{x=0}^{x=1} \Big|_{y=0}^{y=1}\\
&= \frac{1}{3}
\end{aligned}
$$

$$
\begin{aligned}
E[X] &= \int_0^1 x \left(x + \frac{1}{2}\right) dx\\
&= \frac{1}{3} x^3 + \frac{1}{4} x^2 \Big|_{x=0}^{x=1}\\
&= \frac{7}{12}
\end{aligned}
$$

$$E[Y] = E[X] = \frac{7}{12}$$

Putting it all together, we get
$$\mathrm{Cov}(X, Y) = E[XY] - E[X] E[Y] = \frac{1}{3} - \left(\frac{7}{12}\right)^2 = -\frac{1}{144} \approx `r -1/144`$$

## (h)

First, we need variance:
$$
\begin{aligned}
E[X^2] &= \int_0^1 x^2 \left(x + \frac{1}{2}\right) dx\\
&= \frac{1}{4} x^4 + \frac{1}{6} x^3 \Big|_{x=0}^{x=1} \\
&= \frac{5}{12}
\end{aligned}
$$

So, $\mathrm{Var}(Y) = \mathrm{Var}(X) = E[X^2] - E[X]^2 = \frac{5}{12} - \left(\frac{7}{12}\right)^2 = \frac{11}{144}$

Finally, the correlation is
$$\rho(X, Y) = \frac{\mathrm{Cov}(X, Y)}{\sqrt{\mathrm{Var}(X) \mathrm{Var}(Y)}} = \frac{-1 / 144}{\sqrt{(11/144) * (11/144)}} = -\frac{1}{11} \approx `r -1/11`$$

## Problem 4

## (a)

$P(R = a, D = b)$ is non-zero only when $a + b = 4$. Also, notice
throughout this problem that there is a symmetry between the variables $R$ and
$D$. This means that $P(R = a, D = b) = P(R = b, D = a)$. We have

$$
\begin{aligned}
P(R = 4, D = 0) = P(R = 0, D = 4) &= \frac{50 \cdot 49 \cdot 48 \cdot 47}{100
  \cdot 99 \cdot 98 \cdot 97} = \frac{4 \cdot 47}{33 \cdot 97} \approx 0.0587\\
P(R = 3, D = 1) = P(R = 1, D = 3) &= 4 \frac{50 \cdot 49 \cdot 48 \cdot 50}{100
  \cdot 99 \cdot 98 \cdot 97} = \frac{16 \cdot 50}{33 \cdot 97} \approx 0.250\\
P(R = 2, D = 2) &= 6 \frac{50 \cdot 49 \cdot 50 \cdot 49}{100
  \cdot 99 \cdot 98 \cdot 97} = \frac{25 \cdot 49}{33 \cdot 97} \approx 0.383\\
\end{aligned}
$$

## (b)

Using the formula $\mathrm{Cov}(R, D) = E[RD] - E[R]E[D]$

$$
\begin{aligned}
E[RD] &= \sum_{a = 0}^4 \sum_{b = 0}^4 ab \, P(R = a, D = b)\\
&= 3 \cdot (P(R = 3, D = 1) + P(R = 1, D = 3)) + 4 \cdot P(R = 2, D = 2)\\
&= \frac{6 \cdot 16 \cdot 50}{33 \cdot 97} + \frac{4 \cdot 25 \cdot 49}{33 \cdot
  97} = \frac{100}{33} \approx 3.03 \\
\end{aligned}
$$

The marginal pmf's look like this: $P(R = a) = P(R = a, D = 4 - a)$. So,

$$
\begin{aligned}
E[R] &= \sum_{a = 0}^4 a P(R = a, D = 4 - a)\\
& = P(R = 1, D = 3) + 2 \cdot P(R = 2, D = 2) + 3 \cdot P(R = 3, D = 1) + 4
\cdot P(R = 4, D = 0)\\
&= \frac{4 \cdot 16 \cdot 50}{33 \cdot 97} + \frac{2 \cdot 25 \cdot 49}{33 \cdot
  97} + \frac{4 \cdot 4 \cdot 47}{33 \cdot 97} = 2
\end{aligned}
$$

Because of symmetry, $E[D] = E[R]$. Finally, the covariance is
$$
\begin{aligned}
\mathrm{Cov}(R, D) &= E[RD] - E[R]E[D]\\
&= \frac{100}{33} - 2^2 = -\frac{32}{33} \approx -0.9697\\
\end{aligned}
$$

## (c)

Using the formula $\rho(R, D) = \mathrm{Cov}(R, D) / \sqrt{\mathrm{Var}(R) \, \mathrm{Var}(D)}$

$$
\begin{aligned}
E[R^2] &= P(R = 1) + 4 \cdot P(R = 2) + 9 \cdot P(R = 3) + 16 \cdot P(R = 4)\\
&= \frac{1}{33 \cdot 97} \left(16 \cdot 50 + 4 \cdot 25 \cdot 49 + 9 \cdot 16
\cdot 50 + 16 \cdot 4 \cdot 47\right) = \frac{164}{33}
\end{aligned}
$$

$$\mathrm{Var}(R) = E[R^2] - E[R]^2 = \frac{164}{33} - 2^2 = \frac{32}{33}$$

Again, symmetry tells us that $\mathrm{Var}(D) = \mathrm{Var}(R)$. Putting it all together, we
get
$$\rho(R, D) = \mathrm{Cov}(R, D) / \sqrt{\mathrm{Var}(R)\,\mathrm{Var}(D)} = -\frac{32}{33} / \frac{32}{33} = -1$$